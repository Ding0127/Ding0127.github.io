<!DOCTYPE html>
<html lang="zh-CN">

<head>
    <meta charset="UTF-8">
<meta name="viewport"
      content="width=device-width, initial-scale=1.0, maximum-scale=1.0, minimum-scale=1.0">
<meta http-equiv="X-UA-Compatible" content="ie=edge">

    <meta name="author" content="阿泰">





<title>tokenization | Hexo</title>



    <link rel="icon" href="/favicon.ico">




    <!-- stylesheets list from _config.yml -->
    
    <link rel="stylesheet" href="/css/style.css">
    



    <!-- scripts list from _config.yml -->
    
    <script src="/js/script.js"></script>
    
    <script src="/js/tocbot.min.js"></script>
    



    
    
        <!-- MathJax配置，可通过单美元符号书写行内公式等 -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
    "HTML-CSS": {
        preferredFont: "TeX",
        availableFonts: ["STIX","TeX"],
        linebreaks: { automatic:true },
        EqnChunk: (MathJax.Hub.Browser.isMobile ? 10 : 50)
    },
    tex2jax: {
        inlineMath: [ ["$", "$"], ["\\(","\\)"] ],
        processEscapes: true,
        ignoreClass: "tex2jax_ignore|dno",
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    },
    TeX: {
        equationNumbers: { autoNumber: "AMS" },
        noUndefined: { attributes: { mathcolor: "red", mathbackground: "#FFEEEE", mathsize: "90%" } },
        Macros: { href: "{}" }
    },
    messageStyle: "none"
    });
</script>
<!-- 给MathJax元素添加has-jax class -->
<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for(i=0; i < all.length; i += 1) {
            all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<!-- 通过连接CDN加载MathJax的js代码 -->
<script type="text/javascript" async
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-MML-AM_CHTML">
</script>


    


<meta name="generator" content="Hexo 7.3.0"></head>

<body>
    <script>
        // this function is used to check current theme before page loaded.
        (() => {
            const currentTheme = window.localStorage && window.localStorage.getItem('theme') || '';
            const isDark = currentTheme === 'dark';
            const pagebody = document.getElementsByTagName('body')[0]
            if (isDark) {
                pagebody.classList.add('dark-theme');
                // mobile
                document.getElementById("mobile-toggle-theme").innerText = "· Dark"
            } else {
                pagebody.classList.remove('dark-theme');
                // mobile
                document.getElementById("mobile-toggle-theme").innerText = "· Light"
            }
        })();
    </script>

    <div class="wrapper">
        <header>
    <nav class="navbar">
        <div class="container">
            <div class="navbar-header header-logo"><a href="/">Ding&#39;s Blog</a></div>
            <div class="menu navbar-right">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
                <input id="switch_default" type="checkbox" class="switch_default">
                <label for="switch_default" class="toggleBtn"></label>
            </div>
        </div>
    </nav>

    
    <nav class="navbar-mobile" id="nav-mobile">
        <div class="container">
            <div class="navbar-header">
                <div>
                    <a href="/">Ding&#39;s Blog</a><a id="mobile-toggle-theme">·&nbsp;Light</a>
                </div>
                <div class="menu-toggle" onclick="mobileBtn()">&#9776; Menu</div>
            </div>
            <div class="menu" id="mobile-menu">
                
                    <a class="menu-item" href="/archives">Posts</a>
                
                    <a class="menu-item" href="/category">Categories</a>
                
                    <a class="menu-item" href="/tag">Tags</a>
                
                    <a class="menu-item" href="/about">About</a>
                
            </div>
        </div>
    </nav>

</header>
<script>
    var mobileBtn = function f() {
        var toggleMenu = document.getElementsByClassName("menu-toggle")[0];
        var mobileMenu = document.getElementById("mobile-menu");
        if(toggleMenu.classList.contains("active")){
           toggleMenu.classList.remove("active")
            mobileMenu.classList.remove("active")
        }else{
            toggleMenu.classList.add("active")
            mobileMenu.classList.add("active")
        }
    }
</script>
            <div class="main">
                <div class="container">
    
    
        <div class="post-toc">
    <div class="tocbot-list">
    </div>
    <div class="tocbot-list-menu">
        <a class="tocbot-toc-expand" onclick="expand_toc()">Expand all</a>
        <a onclick="go_top()">Back to top</a>
        <a onclick="go_bottom()">Go to bottom</a>
    </div>
</div>

<script>
    var tocbot_timer;
    var DEPTH_MAX = 6; // 为 6 时展开所有
    var tocbot_default_config = {
        tocSelector: '.tocbot-list',
        contentSelector: '.post-content',
        headingSelector: 'h1, h2, h3, h4, h5',
        orderedList: false,
        scrollSmooth: true,
        onClick: extend_click,
    };

    function extend_click() {
        clearTimeout(tocbot_timer);
        tocbot_timer = setTimeout(function() {
            tocbot.refresh(obj_merge(tocbot_default_config, {
                hasInnerContainers: true
            }));
        }, 420); // 这个值是由 tocbot 源码里定义的 scrollSmoothDuration 得来的
    }

    document.ready(function() {
        tocbot.init(obj_merge(tocbot_default_config, {
            collapseDepth: 1
        }));
    });

    function expand_toc() {
        var b = document.querySelector('.tocbot-toc-expand');
        var expanded = b.getAttribute('data-expanded');
        expanded ? b.removeAttribute('data-expanded') : b.setAttribute('data-expanded', true);
        tocbot.refresh(obj_merge(tocbot_default_config, {
            collapseDepth: expanded ? 1 : DEPTH_MAX
        }));
        b.innerText = expanded ? 'Expand all' : 'Collapse all';
    }

    function go_top() {
        window.scrollTo(0, 0);
    }

    function go_bottom() {
        window.scrollTo(0, document.body.scrollHeight);
    }

    function obj_merge(target, source) {
        for (var item in source) {
            if (source.hasOwnProperty(item)) {
                target[item] = source[item];
            }
        }
        return target;
    }
</script>
    

    
    <article class="post-wrap">
        <header class="post-header">
            <h1 class="post-title">tokenization</h1>
            
                <div class="post-meta">
                    
                        Author: <a itemprop="author" rel="author" href="/">阿泰</a>
                    

                    
                        <span class="post-time">
                        Date: <a href="#">二月 3, 2025&nbsp;&nbsp;15:52:43</a>
                        </span>
                    
                    
                        <span class="post-category">
                    Category:
                            
                                <a href="/categories/%E5%A4%A7%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80/">大模型基础</a>
                            
                        </span>
                    
                </div>
            
        </header>

        <div class="post-content">
            <h2 id="Tokenization"><a href="#Tokenization" class="headerlink" title="Tokenization"></a>Tokenization</h2><h3 id="什么是分词"><a href="#什么是分词" class="headerlink" title="什么是分词"></a>什么是分词</h3><p><strong>目的</strong>：分词的目的是将输入文本分成一个个词元，保证各个词元拥有相对完整和独立的语义，供后续任务（比如embedding或者作为高级模型的输入）使用。</p>
<h3 id="分词的三种粒度："><a href="#分词的三种粒度：" class="headerlink" title="分词的三种粒度："></a><strong>分词的三种粒度：</strong></h3><h4 id="1-词粒度（Word-level-Tokenization）"><a href="#1-词粒度（Word-level-Tokenization）" class="headerlink" title="1. 词粒度（Word-level Tokenization）"></a>1. <strong>词粒度（Word-level Tokenization）</strong></h4><ul>
<li><strong>原理</strong>：将文本按自然语言的词汇切分，例如英文按空格分隔单词，中文则需要依赖分词工具（如jieba分词）。<ul>
<li><strong>英文示例</strong>：<code>&quot;I love NLP&quot;</code> → <code>[&quot;I&quot;, &quot;love&quot;, &quot;NLP&quot;]</code></li>
<li><strong>中文示例</strong>：<code>&quot;自然语言处理&quot;</code> → <code>[&quot;自然&quot;, &quot;语言&quot;, &quot;处理&quot;]</code></li>
</ul>
</li>
<li><strong>优点</strong>：<ul>
<li>直接保留语义单元，符合人类直觉。</li>
</ul>
</li>
<li><strong>缺点</strong>：<ul>
<li>无法处理OOV（Out-of-Vocabulary）问题，例如新词或拼写错误（如 <code>&quot;beatiful&quot;</code>，<code>&quot;栓Q&quot;</code>）。</li>
<li>中文分词依赖工具，可能因分词工具不同导致结果差异（如 <code>&quot;机器学习&quot;</code> 是否拆分为 <code>[&quot;机器&quot;, &quot;学习&quot;]</code>）。</li>
<li>词粒度的词表<strong>长尾效应可能会非常大</strong>，包含很多稀有词存储和训练的成本都比较高，并且稀有词往往很难学好。（如专业术语 <code>&quot;脱氧核糖核酸&quot;</code> 或生僻词 <code>&quot;耄耋&quot;</code>）</li>
<li>无法处理单词的形态和词缀关系。<ul>
<li>英文中 <code>&quot;run&quot;</code>（跑）、<code>&quot;ran&quot;</code>（过去式）、<code>&quot;running&quot;</code>（进行时）被当作独立词，无法共享语义</li>
<li>词缀泛化能力差（如 <code>&quot;anti-virus&quot;</code> 和 <code>&quot;anti-war&quot;</code> 中的 <code>&quot;anti-&quot;</code> 无法关联）。</li>
</ul>
</li>
</ul>
</li>
<li><strong>适用场景</strong>：传统NLP任务（如文本分类），但对大模型不友好（因OOV问题）。</li>
</ul>
<hr>
<h4 id="2-子词粒度（Subword-level-Tokenization）"><a href="#2-子词粒度（Subword-level-Tokenization）" class="headerlink" title="2. 子词粒度（Subword-level Tokenization）"></a>2. <strong>子词粒度（Subword-level Tokenization）</strong></h4><ul>
<li><strong>原理</strong>：常用词保持原装，生僻词拆分成subword共享token压缩空间。</li>
<li><strong>优点</strong>：<ul>
<li>平衡词表大小和语义表达能力</li>
</ul>
</li>
<li><strong>适用场景</strong>：绝大多数大模型（如BERT、GPT、T5）均采用子词分词，平衡效率和语义。</li>
</ul>
<hr>
<h4 id="3-字符粒度（Character-level-Tokenization）"><a href="#3-字符粒度（Character-level-Tokenization）" class="headerlink" title="3. 字符粒度（Character-level Tokenization）"></a>3. <strong>字符粒度（Character-level Tokenization）</strong></h4><ul>
<li><p><strong>原理</strong>：将文本按单个字符切分。</p>
<ul>
<li><strong>英文示例</strong>：<code>&quot;hello&quot;</code> → <code>[&quot;h&quot;, &quot;e&quot;, &quot;l&quot;, &quot;l&quot;, &quot;o&quot;]</code></li>
<li><strong>中文示例</strong>：<code>&quot;自然语言&quot;</code> → <code>[&quot;自&quot;, &quot;然&quot;, &quot;语&quot;, &quot;言&quot;]</code></li>
</ul>
</li>
<li><p><strong>优点</strong>：</p>
<ul>
<li>词汇表极小（英文仅26字母+符号，中文约6000常用字）。</li>
<li>彻底解决OOV问题。</li>
</ul>
</li>
<li><p><strong>缺点</strong>：</p>
<ul>
<li>序列长度过长（中文文本长度可能翻倍），计算效率低。<ul>
<li>句子 <code>&quot;自然语言处理技术发展迅速&quot;</code> 以字符拆分后token长度为13，若以词或子词拆分可能仅需6-8个token。</li>
</ul>
</li>
<li>丢失词语的语义信息（如 <code>&quot;自然&quot;</code> 拆分为单字可能丢失整体含义）。<ul>
<li>英文单字母 <code>&quot;c&quot;</code> 在 <code>&quot;cat&quot;</code> 和 <code>&quot;ice&quot;</code> 中承载的语义信息几乎为零。</li>
<li>化学术语 <code>&quot;苯&quot;</code> 单独出现时仅代表一个化学元素，但组合为 <code>&quot;苯甲酸&quot;</code> 时需模型从字符序列重建专业含义。</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>适用场景</strong>：</p>
<ul>
<li>资源受限的小模型，或需要<strong>处理大量拼写错误</strong>的任务（如语音识别纠错）。</li>
<li>中文场景中因汉字数量可控，比英文更实用。</li>
</ul>
</li>
</ul>
<hr>
<h3 id="经典分词算法"><a href="#经典分词算法" class="headerlink" title="经典分词算法"></a>经典分词算法</h3><h4 id="1-BPE（Byte-Pair-Encoding）"><a href="#1-BPE（Byte-Pair-Encoding）" class="headerlink" title="1. BPE（Byte Pair Encoding）"></a>1. BPE（Byte Pair Encoding）</h4><ul>
<li><p><strong>思想</strong>：先把文本中的所有单词拆成最小的单位（通常是字符或Unicode字节），然后逐步**“合并”**最频繁出现的token对来产生新的token，最终获得一个指定大小的词汇表（Vocabulary）。</p>
</li>
<li><p><strong>优点：</strong></p>
<ul>
<li>有效平衡词汇表大小和编码步数。较小的词汇表可能导致编码步数增加（需要更多的 token 来表示句子），而较大的词汇表可能导致存储和计算开销增加。</li>
</ul>
</li>
<li><p><strong>缺点：</strong></p>
<ul>
<li>基于贪婪和确定的符号替换，不能提供带概率的多个分词结果。<ul>
<li><strong>ULM（Unigram Language Model）</strong> 算法可以为每个分词结果分配概率，从而支持多种分词可能性。</li>
</ul>
</li>
<li>Decode 的时候面临歧义问题<ul>
<li>假设词汇表包含 <code>low</code>、<code>er</code>、<code>est</code>。</li>
<li>子词序列 <code>[&quot;low&quot;, &quot;er&quot;, &quot;est&quot;]</code> 和 <code>[&quot;low&quot;, &quot;est&quot;]</code> 都可以解码为 <code>lowest</code>。</li>
<li>BPE 无法判断哪种分词方式更合理。</li>
</ul>
</li>
</ul>
</li>
<li><p><strong>基本流程</strong></p>
<ol>
<li>准备基础词表：比如英文中26个字母加上各种符号。</li>
<li>在语料中统计所有相邻符号对的出现频率，选择频率最高的单元对进行合并</li>
<li>重复直到达到预先设定的subword词表大小或下个最高频率为1</li>
</ol>
</li>
</ul>
<hr>
<h4 id="2-BBPE（Byte-Level-BPE）"><a href="#2-BBPE（Byte-Level-BPE）" class="headerlink" title="2. BBPE（Byte-Level BPE）"></a>2. BBPE（Byte-Level BPE）</h4><ul>
<li><p><strong>简介</strong>：BBPE（Byte-Level BPE）是 OpenAI 在 GPT-2 引入的一种变体。</p>
<ul>
<li>输入的单位改为原始的<strong>字节（byte）</strong>，包括空格、标点以及其他特殊字符都以字节形式处理。基础词表使用256的字节集，UTF-8编码</li>
</ul>
</li>
<li><p><strong>优点</strong></p>
</li>
</ul>
<ol>
<li>效果与BPE相当，但词表大为减少</li>
<li>在多语言情境中，难以穷举所有字符，而字节级别方法更通用。</li>
</ol>
<ul>
<li><p><strong>缺点</strong></p>
<ul>
<li><p>编码序列时，长度可能会略长于 BPE，计算成本更高</p>
</li>
<li><p>由 byte 解码时可能会遇到歧义，需要通过上下文信息和动态规划来进行解码</p>
</li>
</ul>
</li>
</ul>
<hr>
<h4 id="3-WordPiece"><a href="#3-WordPiece" class="headerlink" title="3. WordPiece"></a>3. WordPiece</h4><ul>
<li><p><strong>简介</strong>：与BPE类似，从一个基础小词表出发，通过不断合并来产生最终的词表。</p>
<ul>
<li>**区别：**BPE按频率来选择合并的token对，而wordpiece按token间的互信息来进行合井</li>
</ul>
</li>
<li><p><strong>基本流程</strong></p>
<ul>
<li><p>准备基础词表，对于英文，通常先包含 26 个字母以及标点符号、特殊符号等最小单位。</p>
</li>
<li><p>基于基础词表将语料拆分为最小单元</p>
<ul>
<li>对于英文，如果基础词表仅包含字符，语料就会被拆成字符序列。</li>
</ul>
</li>
<li><p>训练语言模型，通过极大似然估计</p>
<ul>
<li><p>可以使用 Unigram Language Model（或其他类似的一元模型）来计算子词出现的概率；也可能直接统计联合概率或条件概率，来评估合并后的对整体概率的增益。</p>
</li>
<li><p>目的是为后续判断“哪些 token 对的合并对整体语料的概率提升贡献最大”做准备。</p>
</li>
<li><p>根据互信息（或得分公式）选择要合并的 token 对</p>
</li>
<li><p>逐一从所有可能出现的 token 对中挑选，将得分最高的那对 token 合并成一个新子词单元，更新统计频次。</p>
</li>
<li><p>重复合并，直到达到预设的词表大小或增益低于阈值</p>
</li>
</ul>
</li>
</ul>
<p>$$<br>\text{score}(w_1, w_2) &#x3D; \log \frac{\text{count}(w_1, w_2)}{\text{count}(w_1) \times \text{count}(w_2)}<br>$$</p>
</li>
<li><p><strong>优势</strong></p>
<ul>
<li>平衡词表大小和OOV问题</li>
</ul>
</li>
<li><p><strong>缺点</strong></p>
<ul>
<li>可能会产生一些不太合理的子词或者说错误的切分对拼写错误非常敏感;对前缀的支持不够好<ul>
<li>一种解决方案是:将复合词拆开、将前缀也拆开</li>
</ul>
</li>
</ul>
</li>
</ul>
<hr>
<h4 id="4-ULM（Unigram-Language-Model-）"><a href="#4-ULM（Unigram-Language-Model-）" class="headerlink" title="4. ULM（Unigram Language Model ）"></a>4. ULM（Unigram Language Model ）</h4><ul>
<li><strong>核心思想</strong>：初始化一个大词表，然后通过Unigram语言模型计算删除不同subword造成的损失来代表subword的重要性，保留loss较大的subword<ul>
<li>unigram model：假设每个词都是独立的</li>
</ul>
</li>
<li><strong>具体做法</strong>：<ol>
<li>初始化一个很大的词表</li>
<li>尝试删除一个token,并计算对应的unigram loss</li>
<li>将字词按照loss大小排序，保留前x%的字词；单字符不能被丢弃，以免OOV</li>
<li>迭代直到词表的大小缩减到预设值</li>
</ol>
</li>
</ul>
<p>为单词的每种划分计算概率非常耗时，采用更高效的维特比(Viterbi)算法</p>
<ul>
<li><strong>优点</strong>：<ol>
<li>可以利用所有可能的分词结果，这是通过数据采样算法实现的</li>
<li>为多种分词结果赋予概率，在噪音场景下能保持一定的稳健性</li>
</ol>
</li>
<li><strong>缺点</strong>:<ul>
<li>初始词表要足够丰富，往往是BPE生成在做扩展，如果初始词表不够全就会收到限制，无法凭空创造出更多的新字词</li>
<li>算法相对复杂，消耗时间和内存</li>
</ul>
</li>
</ul>
<hr>
<h4 id="5-SentencePiece"><a href="#5-SentencePiece" class="headerlink" title="5. SentencePiece"></a>5. SentencePiece</h4><ul>
<li><p><strong>参考资料</strong>：<a target="_blank" rel="noopener" href="https://github.com/google/sentencepiece">https://github.com/google/sentencepiece</a></p>
</li>
<li><p><strong>核心思想</strong>：SentencePiece 直接将文本转换为 Unicode 字符序列，无需预处理。直接处理混合语言文本（如中英混合），无需预分词或语言检测。</p>
</li>
<li><p><strong>编解码可逆性</strong></p>
<ul>
<li>显式用 <code>▁</code>（Unicode U+2581）表示空格，作为基本标记的一部分。编码时保留原始空格信息，解码时可完全还原原始文本。</li>
</ul>
</li>
</ul>

        </div>

        
            <section class="post-copyright">
                
                    <p class="copyright-item">
                        <span>Author:</span>
                        <span>阿泰</span>
                    </p>
                
                
                
                

            </section>
        
        <section class="post-tags">
            <div>
                <span>Tag(s):</span>
                <span class="tag">
                    
                    
                        <a href="/tags/%E5%88%86%E8%AF%8D/"># 分词</a>
                    
                        
                </span>
            </div>
            <div>
                <a href="javascript:window.history.back();">back</a>
                <span>· </span>
                <a href="/">home</a>
            </div>
        </section>
        <section class="post-nav">
            
                <a class="prev" rel="prev" href="/2025/02/04/hashtable/">hot100-哈希表</a>
            
            
            <a class="next" rel="next" href="/2025/01/05/2025%20%E7%AC%AC%E4%B8%80%E5%AD%A3%E5%BA%A6%E5%81%9A%E8%A6%81%E7%9A%84%E4%BA%8B/">第一季度</a>
            
        </section>


    </article>
</div>

            </div>
            <footer id="footer" class="footer">
    <div class="copyright">
        <span>© 阿泰 | Powered by <a href="https://hexo.io" target="_blank">Hexo</a> & <a href="https://github.com/Siricee/hexo-theme-Chic" target="_blank">Chic</a></span>
    </div>
</footer>

    </div>
</body>

</html>